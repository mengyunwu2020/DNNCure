{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to implement our method on the SS3 examples from our paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "In this example, a high-dimensional dataset with 300 covariates and 600 observations is generated using the following functions:\n",
    "\n",
    "$$\n",
    "m_L(\\boldsymbol{z} * \\boldsymbol{w}_L) = 0.8\\sum_{j=1}^{10} \\sin(\\boldsymbol{z}_{j})\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "m_C(\\boldsymbol{z} * \\boldsymbol{w}_C) = 0.5\\sum_{j=1}^{10} \\sin(\\boldsymbol{z}_{j}).\n",
    "$$\n",
    "\n",
    "That is, among the 300 covariates, only the first 10 variables in the 'L' and 'C' parts actually contribute to the response. Our task is to correctly select the important variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.random import normal, rand\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import itertools\n",
    "from itertools import product\n",
    "from modelsn import Net_nonlinear\n",
    "import torch.optim as optim\n",
    "from MFS import FS_epoch, total_loss, training_n\n",
    "from tqdm import tqdm\n",
    "from numpy.random import gamma\n",
    "from dt_g import generate_data,generate_Z\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import csv\n",
    "from main import metric\n",
    "from Cindex_AUC import cindex_AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- $Z$ is the $n\\times p$ covariate matrix;\n",
    "- $T$ represents the observation time;\n",
    "- $delta$ indicates censoring status;\n",
    "- $tau$ is the set of event times in sorted order;\n",
    "- $Rj$ denotes the set of samples at risk;\n",
    "- $beta$ represents the probability of cure;\n",
    "- $alpha$ is the total censoring rate minus the cure probability;\n",
    "- $ll =\\lambda_3\\times p$, which is used to control the similarity between the variable selection results of the L and C components. \n",
    "\n",
    "\n",
    "For detailed data generation procedures, please refer to the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "-  $s1=s_L,\\quad s2=s_C $, the numbers of variables to be selected in part L and part C respectively;\n",
    "-   epochs, the number of iterations to be run;\n",
    "-   n_hidden1 & n_hidden2, the number of neurons in the fully connect network;\n",
    "-   learning_rate, the learning rate for optimizer;\n",
    "-   Ts & step, the parameters to control the optimization on given support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name='result.csv'\n",
    "seed=1234\n",
    "alpha=0.05\n",
    "beta=0.3\n",
    "f='SS3'\n",
    "n=600\n",
    "p=300\n",
    "s1=11\n",
    "s2=12\n",
    "learning_rate=0.0005\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 10\n",
    "epochs=5#TTo avoid long time waiting, we set a smaller number of epochs in this case\n",
    "Ts=25\n",
    "step=5\n",
    "ll=20\n",
    "Z=generate_Z(seed,n,p)\n",
    "T, delta, tau, d, Rj, idx,y_cure= generate_data(device,seed,f,Z,n,p,alpha,beta)\n",
    "# Define Model\n",
    "model = Net_nonlinear(n_feature=p, n_hidden1=n_hidden1, n_hidden2=n_hidden2,n_output=1).to(device=device)\n",
    "best_model = Net_nonlinear(n_feature=p, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=1).to(device=device)\n",
    "# Define optimizers for the optimization with given support\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=learning_rate, weight_decay=0.0025)\n",
    "optimizer0_1 = torch.optim.Adam(model.hidden0_1.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "optimizer0_2 = torch.optim.Adam(model.hidden0_2.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "hist = []\n",
    "SUPP1 = []\n",
    "SUPP2 = []\n",
    "supp_x1 = list(range(p)) # initial support of part L\n",
    "supp_x2 = list(range(p)) # initial support of part C\n",
    "supp_x=[supp_x1,supp_x2]\n",
    "SUPP1.append(supp_x1)\n",
    "SUPP2.append(supp_x2)\n",
    "data=[Z, T, delta, tau, d, Rj, idx]\n",
    "n,p=Z.shape\n",
    "eta= torch.rand(n).to(device=device)\n",
    "eta[delta==1]=1\n",
    "# eta.requires_grad = False\n",
    "k = len(tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108, 152]\n",
      "loss tensor(3.8604, grad_fn=<AddBackward0>)\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 38, 108]\n",
      "loss tensor(3.2554, grad_fn=<AddBackward0>)\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108, 123]\n",
      "loss tensor(3.2052, grad_fn=<AddBackward0>)\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108, 294]\n",
      "loss tensor(3.2223, grad_fn=<AddBackward0>)\n",
      "epoch: 4\n",
      "L-part: [10, 37, 281, 282, 283, 284, 285, 286, 287, 288, 289] C-part: [10, 11, 37, 279, 280, 281, 282, 283, 284, 285, 286, 287]\n",
      "loss tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "best_supp [[2, 6, 7, 5, 9, 8, 0, 3, 108, 4, 1], [0, 9, 8, 1, 4, 3, 6, 2, 5, 7, 108, 123]]\n",
      "TPRC: 1.0 FPRC: 0.006896551724137931 TPRL: 1.0 FPRL: 0.0034482758620689655 C-index: 0.9251336898395722 AUC: 0.8388278388278388\n"
     ]
    }
   ],
   "source": [
    "### Algorithm\n",
    "for i in range(epochs):\n",
    "    print('epoch:',i)\n",
    "    # One DFS epoch\n",
    "    model, supp_x,LOSS,eta=FS_epoch(model, s1,s2, supp_x,data, optimizer, optimizer0_1, optimizer0_2,eta, Ts, step,ll)\n",
    "    # supp_x.sort()\n",
    "    _,loss=total_loss (data,model,eta,ll)\n",
    "    print('loss',loss)\n",
    "    hist.append(loss.data.cpu().numpy().tolist())\n",
    "    SUPP1.append(supp_x[0])\n",
    "    SUPP2.append(supp_x[1])\n",
    "    # Prevent divergence of optimization over support, save the current best model\n",
    "    if hist[-1] == min(hist):\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "        best_supp = supp_x\n",
    "        #print(best_supp)\n",
    "    #Early stop criteria\n",
    "    if ((len(SUPP1[-1])==len(SUPP1[-2])) & (len(SUPP2[-1])==len(SUPP2[-2]))):\n",
    "\n",
    "        if((set(SUPP1[-1])==set(SUPP1[-2])) & (set(SUPP2[-1])==set(SUPP2[-2]))) :\n",
    "            break\n",
    "print(loss)\n",
    "best_supp[0],best_supp[1]=list(best_supp[0]),list(best_supp[1])\n",
    "print('best_supp',best_supp)\n",
    "correct_set1=list(range(10))\n",
    "correct_set2=list(range(10))\n",
    "Z_test=generate_Z(seed+1,n//10,p)\n",
    "T_test, delta_test, _, _, _, _,y_cure_test= generate_data(device,seed,f,Z_test,n//10,p,alpha,beta)\n",
    "cindex,AUC=cindex_AUC(T_test, Z_test, delta_test, best_model,y_cure_test,'True')\n",
    "TPRL,FPRL=metric(correct_set1,best_supp[0],seed, f, alpha,beta,n,p,'f1')\n",
    "TPRC,FPRC=metric(correct_set2,best_supp[1],seed, f, alpha,beta,n,p,'f2')\n",
    "print('TPRC:',TPRC,'FPRC:',FPRC,'TPRL:',TPRL,'FPRL:',FPRL,'C-index:',cindex,'AUC:',AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We regenerated a test set with a sample size of n/10 to calculate the AUC and C-index. In terms of variable selection results, the algorithm correctly identified 10 influential variables for both Part L and Part C. It made 1 error in selecting variables for Part L and 2 errors for Part C. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of $s_L$, $s_C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "tensor(3.2250, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 55]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 294]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 158]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 55]\n",
      "tensor(3.1432, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 192]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 294]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 191]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 192]\n",
      "tensor(3.1233, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 191, 192]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 158, 294]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 83, 213]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 191, 192]\n",
      "tensor(3.1354, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 108, 230, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 35, 191, 192]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 46, 158, 294]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 83, 133, 294]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 35, 191, 192]\n",
      "tensor(3.1467, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "tensor(3.1436, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "tensor(3.2142, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 192]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 191]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 83]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 192]\n",
      "tensor(3.1322, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 191]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 158]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 133]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 191]\n",
      "tensor(3.1248, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 108, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 83, 191]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 158, 294]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 49, 232]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 83, 191]\n",
      "tensor(3.1361, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 38, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 49, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 208, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "tensor(3.1550, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 49] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 288] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "tensor(3.1346, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "tensor(3.2133, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13]\n",
      "tensor(3.1100, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 233]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 83]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 294]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 133]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 83]\n",
      "tensor(3.1217, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 38, 108, 233] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 134, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 49, 51, 283] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 49, 287, 288] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 134, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "tensor(3.1674, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 38, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 51, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 49, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 191, 288] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 51, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "tensor(3.1460, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "tensor(3.1316, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 191]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 191]\n",
      "tensor(3.1448, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 226]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 233] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 191]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 294] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 51]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 83] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 51]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 233] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 191]\n",
      "tensor(3.1311, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 38, 88, 108, 233] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 51, 134, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 49, 147, 179, 283] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 138, 208, 287, 288] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 51, 134, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "tensor(3.1790, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 38, 88, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 51, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 49, 208, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 231, 283, 288] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 51, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "tensor(3.1575, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 49, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 208, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "tensor(3.1425, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 226]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 51]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 49, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287]\n",
      "epoch: 4\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 283, 287] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 287]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 147, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 51]\n",
      "tensor(3.1556, grad_fn=<AddBackward0>)\n",
      "epoch: 0\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 111, 226]\n",
      "epoch: 1\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 108] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 226]\n",
      "epoch: 2\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 191]\n",
      "epoch: 3\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 191]\n",
      "L-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 191] C-part: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 88, 191]\n",
      "tensor(3.1145, grad_fn=<AddBackward0>)\n",
      "C-part:Sselected: 12 L-part:Sselected: 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=5\n",
    "hist = []\n",
    "supp_x1=supp_x2 = list(range(p)) # initial support\n",
    "supp_x=[supp_x1,supp_x2]\n",
    "eta_o = torch.rand(n).to(device=device)\n",
    "eta_o[delta==1]=1\n",
    "original_list = [9,10,11,12,13]# We shorten the candidates list in the notebooks\n",
    "Ss = list(itertools.product(original_list, repeat=2))\n",
    "BIC = [] # Store the bic for different s\n",
    "S_num=[]\n",
    "best_model = Net_nonlinear(n_feature=p, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=1)\n",
    "for s in Ss:\n",
    "    # Training dataset  with given s\n",
    "    s1=s[0]\n",
    "    s2=s[1]\n",
    "    eta=eta_o\n",
    "    loss,model,supp,bic= training_n(data,s1,s2,eta, epochs=epochs, n_hidden1=n_hidden1, n_hidden2=n_hidden2, learning_rate=0.0005, Ts=25, step=5,ll=20)\n",
    "    # Store bic values\n",
    "    BIC.append(bic)\n",
    "    S_num.append(len(supp))\n",
    "    if bic == min(BIC):\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "        best_supp = supp\n",
    "    mid_result=[seed,s1,s2,loss,n,len(supp[0]),len(supp[1])]\n",
    "    # with open('hist'+save_file_name, 'a', newline='') as file:\n",
    "    #     writer = csv.writer(file)\n",
    "    #     if file.tell() == 0:\n",
    "    #         writer.writerow([\"seed\", \"s1\",\"s2\",\"loss\",\"n\",\"Ss1\",\"Ss2\"])\n",
    "    #     writer.writerow(mid_result)\n",
    "idx = np.argmin(BIC)\n",
    "best_s1 = Ss[idx][0]\n",
    "best_s2 = Ss[idx][1]\n",
    "print('C-part:Sselected:',best_s2,'L-part:Sselected:',best_s1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
